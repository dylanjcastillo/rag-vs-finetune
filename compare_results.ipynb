{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import chromadb\n",
    "\n",
    "chroma = chromadb.Client()\n",
    "try:\n",
    "    chroma.delete_collection(\"rag\")\n",
    "except:\n",
    "    pass\n",
    "chroma_collection = chroma.create_collection(\"rag\")\n",
    "\n",
    "with open(\"cities_population.jsonl\", \"r\") as f:\n",
    "    jsonl_data = f.read()\n",
    "\n",
    "data = []\n",
    "for row in jsonl_data.split(\"\\n\"):\n",
    "    data.append(json.loads(row)[\"messages\"])\n",
    "\n",
    "assistant_responses = []\n",
    "ids = []\n",
    "for i, message in enumerate(data):\n",
    "    assistant_responses.append(message[2][\"content\"])  \n",
    "    ids.append(str(i))\n",
    "\n",
    "chroma_collection.add(\n",
    "    documents=assistant_responses,\n",
    "    ids=ids,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI \n",
    "from chromadb import QueryResult\n",
    "\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MODEL_ID = \"\"\n",
    "openai_client = OpenAI() \n",
    "\n",
    "def get_prompt(question: str, documents: QueryResult):\n",
    "    context = \"\"\n",
    "    for i, (_, document) in enumerate(\n",
    "        zip(documents[\"metadatas\"][0], documents[\"documents\"][0])\n",
    "    ):\n",
    "        context += f\"[{i}]: \\n\" + document + \"\\n\\n\"\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Answer the following QUESTION based on the CONTEXT only. Only answer from the Context. If you don't know the answer, say 'I don't know'.\\n\\nQUESTION: {question}\\n\\nCONTEXT: {context}\\n\\nANSWER:\"\"\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_fixed(1))\n",
    "def get_completion(messages, model):\n",
    "    return openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        max_tokens=400,\n",
    "        temperature=0.0,\n",
    "        seed=42,\n",
    "        timeout=5\n",
    "    )\n",
    "\n",
    "\n",
    "def get_rag_answer(question: str, context: str, model: str):\n",
    "    messages = get_prompt(question, context)\n",
    "    response = get_completion(messages, model)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def get_finetuned_answer(question: str):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Answer this question to the best of your ability. If you don't know the answer, say 'I don't know'.\\n\\nQUESTION: {question}\\n\\nANSWER:\"\"\"\n",
    "        },\n",
    "    ]\n",
    "    response = get_completion(messages, MODEL_ID)\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons = []\n",
    "for i, row in enumerate(data):\n",
    "    question = row[1][\"content\"]\n",
    "    documents = chroma_collection.query(\n",
    "        query_texts=[question],\n",
    "        n_results=5\n",
    "    )\n",
    "    response_comparison = {\n",
    "        \"response_model_ft\": get_finetuned_answer(question),\n",
    "        \"response_model_rag\": get_rag_answer(question, documents, \"gpt-3.5-turbo-1106\"),\n",
    "        \"answer\": row[2][\"content\"],\n",
    "        \"question\": question,\n",
    "    }\n",
    "    print(i, response_comparison)\n",
    "    comparisons.append(response_comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_number(text):\n",
    "    matches = re.findall(r\"\\s(\\d+)\", text)\n",
    "    if len(matches) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return int(matches[0])\n",
    "\n",
    "correct_ft = 0\n",
    "correct_rag = 0\n",
    "for comparison in comparisons:\n",
    "    ft_number = extract_number(comparison[\"response_model_ft\"])\n",
    "    rag_number = extract_number(comparison[\"response_model_rag\"])\n",
    "    answer_number = extract_number(comparison[\"answer\"])\n",
    "    print(ft_number, rag_number, answer_number)\n",
    "\n",
    "    if ft_number == answer_number:\n",
    "        correct_ft += 1\n",
    "    if rag_number == answer_number:\n",
    "        correct_rag += 1\n",
    "\n",
    "print(\"Accuracy FT:\", correct_ft / len(comparisons))\n",
    "print(\"Accuracy RAG:\", correct_rag / len(comparisons))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
